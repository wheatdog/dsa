%
% Homework Details
%   - Title
%   - Due date
%   - University
%   - Class
%   - Class Alias
%   - Class Section
%   - Instructor
%   - Author
%   - AuthorID
%

\newcommand{\hmwkID}{6} % Need to be filled in
\newcommand{\hmwkTitle}{Homework\ \#\hmwkID}
\newcommand{\hmwkDueDate}{June 9, 2015 at 16:20} % Need to be filled in
\newcommand{\hmwkUniversity}{NTU}
\newcommand{\hmwkClass}{Data Structures and Algorithms}
\newcommand{\hmwkClassAlias}{DSA}
\newcommand{\hmwkClassSection}{Spring 2015}
\newcommand{\hmwkClassInstructor}{Hsuan-Tien Lin, Roger Jang}
\newcommand{\hmwkAuthorName}{Tim Liou}
\newcommand{\hmwkAuthorID}{b03902028}


\input{../../dep/dsa-hw-template.tex}
\usepackage{qtree}

\begin{document}

\pagenumbering{gobble}

\maketitle

\pagebreak

\pagenumbering{arabic}  

\begin{homeworkProblem}{Skip List, Binary Search Tree}
    \begin{enumerate}[label=(\arabic*)]
        \item Do Exercise C-9.15 of the textbook.

            For every node, also store the width of the link. The width is 
            defined as the number of bottom layer links being traversed by each
            of the higher layer "express lane" links. Following is 
            Example from \texttt{http://en.wikipedia.org/wiki/Skip\_list\#Indexable\_skiplist}

    \begin{verbatim}
   1                               10
 o---> o---------------------------------------------------------> o   Top
   1           3              2                    5
 o---> o---------------> o---------> o---------------------------> o    
   1        2        1        2                    5
 o---> o---------> o---> o---------> o---------------------------> o   
   1     1     1     1     1     1     1     1     1     1     1 
 o---> o---> o---> o---> o---> o---> o---> o---> o---> o---> o---> o   Bottom
                                         
Head  1st   2nd   3rd   4th   5th   6th   7th   8th   9th   10th  NIL
      Node  Node  Node  Node  Node  Node  Node  Node  Node  Node
    \end{verbatim}

            \begin{algorithm}[]
                \begin{algorithmic}[1]
                    \Function{Median}{}
                    \State{node $\gets$ head}
                    \State{remain $\gets \left \lfloor{\frac{n}{2}}\right \rfloor $}
                    \While{\Call{Below}{node} $\neq$ null}
                    \State{node $\gets$ \Call{Below}{node}}
                        \While{remain $\geq$ \Call{Width}{node}}
                            \State{remain $\gets$ remain $-$ \Call{Width}{node}}
                            \State{node $\gets$ \Call{After}{node}}
                        \EndWhile
                    \EndWhile
                    \State{\Return{node}}
                    \EndFunction{}
                \end{algorithmic}
                \caption{Find the median element}
            \end{algorithm}
            We can use \alg{Width} function to get the width in $O(1)$ since we
            store the value. This \alg{Median} function involes two nested 
            \alg{while} loops. One performs a scan forward, and the other drops 
            down to the next level. Since the height $h$ of $S$ is $O(\log n)$
            with high probability, the number og drop-down steps is $O(\log n)$
            with high probability. Let $n_i$ be the number of keys examined while
            scanning forward at level $i$. We can easily observe that, after the
            key at the starting postion, each additional key examined in a 
            scan-forward at level $i$ cannot also belong to level $i+1$. If any
            of these keys were on the previous level, we would have encountered
            them in the previous level. Thus, the expected value of $n_i$ is 
            exactly equal to the expected number of times we must flip a fair
            coin before it comes up heads, That is 2. Hence, the expected amount
            of time spent scanning forward at any level $i$ is $O(1)$. Since
            $S$ has $O(\log n)$ levels with high probability, this \alg{Median}
            function in $S$ takes expected time $O(\log n)$.


            
        \item Do Exercise R-10.5 of the textbook.

            Consider these two input orders, $\left\{\,1,3,2,4,5\,\right\}$ and
            $\left\{\,4,2,1,5,3\,\right\}$. Note that these two sets contain
            same entries $\left\{\,1,2,3,4,5\,\right\}$. We can easily find 
            that they generate different trees.
            \begin{figure}[h]
                \Tree [.1 $\square$ [ [ $\square$ $\square$ ].2 [ $\square$ [ $\square$ $\square$ ].5 ].4 ].3 ]
                \Tree [.4 [ [ $\square$ $\square$ ].1 [ $\square$ $\square$ ].3 ].2 [ $\square$ $\square$ ].5 ]
                \caption{Left tree generates from $\left\{\,1,3,2,4,5\,\right\}$,
                and right tree generates from $\left\{\,4,2,1,5,3\,\right\}$.}
            \end{figure}

            We conclude that the order of insertion does matter.

        \item Do Exercise C-10.12 of the textbook.

            Consider this AVL tree.

            \Tree [.25 [ [ 3 \\ ].5 [ 12 20 ].13 ].11 [ 27 40 ].37 ]

            After insert 4, it becomes unbalanced.

            \Tree [.25 [ [ [ \\ 4 ].3 \\ ].5 [ 12 20 ].13 ].11 [ 27 40 ].37 ]

            We can easily find that the unbalanced nodes are 5 and 25, which
            are nonconsecutive.

            Then, consider this case.

            \Tree [.25 [ 5 [ 12 20 ].13 ].11 [ 27 40 ].37 ]

            After insert 21, it becomes unbalanced, and the unbalanced nodes are
            13, 11 and 25, which are consecutive.

            \Tree [.25 [ 5 [ 12 [ \\ 21 ].20 ].13 ].11 [ 27 40 ].37 ]

            We conclude that the nodes that become unbalanced in an AVL tree during an
            \texttt{insert} operation may be nonconsecutive on the path from the newly
            inserted node to the root.


    \end{enumerate}
\end{homeworkProblem}

\begin{homeworkProblem}{Balanced Binary Search Trees}
    \begin{enumerate}[label=(\arabic*)]
        \item
            Write a program \texttt{hw6\_2} that reads 32 strings (of length at
            most 128 that can be compared lexicographically) line by line (each 
            line containing one string) from \texttt{stdin} and inserts them to
            the AVL tree (\texttt{avl.c}), height-bounded binary search tree 
            (\texttt{bst.c}), and Red-Black tree (\texttt{rb.c}). Please output
            the resulting trees (pre-order) to \texttt{stdout} with specific
            format. 

            Input:
            \lstinputlisting[breaklines=true]{../code/test/hw6_2.ckeyword.in}

            Output:
            \lstinputlisting[breaklines=true]{../code/test/hw6_2.ckeyword.out}

    \end{enumerate}
\end{homeworkProblem}

\pagebreak

\begin{homeworkProblem}{Disjoint Set}
    \begin{enumerate}[label=(\arabic*)]
        \item
            Prove that the disjoint-set forest with this heuristic yields a 
            worst-case running time for find and union within $O(\log n)$.

            We can provide a variable stored the height in every node. By doing 
            so, \texttt{union} only take $O(1)$ since we just change the pointer
            of root in shorter tree to the root of taller tree.

            The worse-case running time of \texttt{find} depends on the depth of 
            the tree.

            We will prove that each \texttt{union} operation keeps trees within 
            depth $O(\log n)$ by showing that within the forest, any tree of 
            height $h$ always contains at least $2^h$ nodes.

            \begin{itemize}
                \item Base case: It is trivial that $h = 0$ is right.
                \item Inductive hypothesis: assume true for $h - 1$. 
                \item A tree of height $h$ is created only by \texttt{union}
                    two trees of height $h - 1$
                \item By inductive hypothesis, each subtree has $\geq 2^{h-1}$
                    nodes $\Rightarrow$ resulting tree has $\geq 2^{h}$
            \end{itemize}

            We proved that any tree of height $h$ always contains at least $2^h$
            nodes. That is, For any tree containing $n$ nodes, the height is 
            $O(\log n)$. We can conclude that the worst-case running time for
            \texttt{find} is also within $O(\log n)$.

        \item
            Suppose that you only need to output $u$ rather than $u$ and $k$ for
            this problem. Write down the pseudo-code of an efficient algorithm
            based on the disjoint forest.

            \begin{algorithm}[]
                \begin{algorithmic}[1]
                    \Function{Owner}{id, OwnerTable}
                    \State{t $\gets$ \Call{Find}{id}}
                    \State{\Return{OwnerTable[t]}}
                    \EndFunction{}
                \end{algorithmic}
                \caption{An efficient algorithm to output $u$ based on the disjoint forest.}
            \end{algorithm}

            An array \alg{OwnerTable} store the real owner of every sets in the index 
            of the top node of the tree. Everytime we \alg{Union} two sets, we will 
            adjust \alg{OwnerTable} properly.

            \pagebreak
        \item
            Suppose that the prices of your friend $u$'s games are stored in a
            balanced BST as keys, and you have access to the size and the sum of
            all keys of any subtree of the BST in an $O(1)$ time, write down the
            pseudo-code of an efficient algorithm for outputting $k$ for the 
            particular $u$.

            \begin{algorithm}[]
                \begin{algorithmic}[1]
                    \Function{GameNumCanBuy}{\emph{m, root}}
                    \State{num $\gets$ 0}
                    \If{the sum of all keys in root's left subtree $>$ m}
                        \State{\Return{\Call{GameNumCanBuy}{\emph{m, root's left node}}}}
                    \EndIf
                    \State{m $\gets$ m - the sum of all keys in root's left subtree}
                    \State{num $\gets$ num + the size of root's left subtree}
                    \While{duplicate key count $>$ 0}
                    \If{m $<$ the key of the root}
                    \State{break the while loop}
                    \EndIf
                        \State{m $\gets$ m - the key of root}
                        \State{num $\gets$ num + 1}
                        \State{duplicate key count $\gets$ duplicate key count $-$ 1}
                    \EndWhile
                    \If{the sum of all keys in root's right subtree $>$ m}
                        \State{num $\gets$ num + \Call{GameNumCanBuy}{\emph{m, root's right node}}}
                    \EndIf
                    \State{m $\gets$ m - the sum of all keys in root's right subtree}
                    \State{num $\gets$ num + the size of root's right subtree}
                    \State{\Return{num}}
                    \EndFunction{}
                \end{algorithmic}
                \caption{Find the maximum number of games can buy with m dollars}
            \end{algorithm}

        \item
            If we take the same heuristic as (1) and always insert the elements
            of the smaller BST into the bigger one, prove that processing all
            incidents of the first kind takes $O(n(\log n)^2)$ time.

            The worst case is that we always \alg{Union} two BSTs of same size. 
            Suppose $n = 2^{k+1}$, \alg{Union} all BSTs in this case, 

            \begin{align*}
                1 \log_2{2} + 2 \log_2{4} + 4 \log_2{8} + \cdots + 2^{k-1} \log_2{2^k} + 2^k \log_2{2^{k+1}} &\leq (k+1) \times 2^k \log_2{2^{k+1}}  \\
                &= (k+1)^2 \times 2^k \\
                &\leq (k+1)^2 \times 2^{k+1} \\
                &= \frac{1}{(\log2)^2} \times n (\log n)^2
            \end{align*}

            It implies that processing all incidents of the first kind takes $O(n(\log n)^2)$ time.

    \end{enumerate}
\end{homeworkProblem}

\end{document}
